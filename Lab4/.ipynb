{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model with unnormalized sentences\n",
      "(2061, 1519) (2061,)\n",
      "Accuracy =  0.8792749774441209\n",
      "\n",
      "Logistic Rregression with normalized sentences\n",
      "(2061, 5155) (2061,)\n",
      "Accuracy =  0.9093433657177799\n",
      "\n",
      "Naive Bayes with unnormalized sentences\n",
      "(2061, 1519) (2061,)\n",
      "Accuracy =  0.89453290960692\n",
      "\n",
      "Naive Bayes with normalized sentences\n",
      "(2061, 5155) (2061,)\n",
      "Accuracy =  0.9215161120810944\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import numpy as npy\n",
    "import pandas as panda\n",
    "from nltk import word_tokenize\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer # term frequency-inverse document frequency (td-idf)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score #for calculating accuracy\n",
    "from io import StringIO\n",
    "\n",
    "class sentimentClass:\n",
    "    \n",
    "    def __init__(self, normalize=True, classifier = \"logReg\", split_ratio=0.3):\n",
    "        #Initializes the classifier\n",
    "\n",
    "        if classifier == \"logReg\":\n",
    "            self.classifier = LogisticRegression(solver='lbfgs',multi_class='multinomial')\n",
    "        elif classifier == \"NB\":\n",
    "            self.classifier = naive_bayes.MultinomialNB()\n",
    "            \n",
    "        self.normalize = normalize\n",
    "        if self.normalize:\n",
    "            self.vector = TfidfVectorizer(use_idf=True)\n",
    "        else:\n",
    "            self.vector = TfidfVectorizer(use_idf=True, lowercase = True, stop_words = set(nltk.corpus.stopwords.words('english')), strip_accents='unicode', ngram_range=(1, 2), max_df=0.85, min_df=3, sublinear_tf=True)\n",
    "            \n",
    "    def curate(self, sentence):\n",
    "        #creates tables of vectors which we can fit onto the data \n",
    "        return self.vector.transform(sentence.review)\n",
    "    \n",
    "    \n",
    "    def readFile(self, files):\n",
    "        #Reads all the files and creates one frame for all of them using pandas library\n",
    "        info = []\n",
    "        X,Y = [], []\n",
    "        for x in files:\n",
    "            strippedInfo = panda.read_csv(x, sep='\\t', names=['review','label'])\n",
    "            info.append(strippedInfo)\n",
    "        info = panda.concat(info)\n",
    "        self.info = info\n",
    "        Y = info.label\n",
    "        self.vector.fit(info.review)\n",
    "        X = self.curate(info)\n",
    "        \n",
    "        return train_test_split(X,Y)\n",
    "    \n",
    "    \n",
    "    def trainFunc(self, files):\n",
    "        #trains the classifier using already built in libraries \n",
    "        X_train, X_test, Y_train, Y_test =  self.readFile(files)                      \n",
    "        self.classifier.fit(X_train,Y_train)\n",
    "        print (X_train.shape,Y_train.shape)     \n",
    "        accuracy = roc_auc_score(Y_test,self.classifier.predict_proba(X_test)[:,1])\n",
    "        \n",
    "        #prints out the accuracy of the classification\n",
    "        print (\"Accuracy = \",accuracy)\n",
    "        \n",
    "        \n",
    "    def classification(self, sentence):\n",
    "        #Attempts the classification of any sentence parsed to it \n",
    "        classf = panda.read_csv(StringIO(sentence), names=['review'])\n",
    "        X = self.curate(classf)\n",
    "        \n",
    "        #Log of probability estimates.The returned estimates for all classes are ordered by the label of classes\n",
    "        Y = self.classifier.predict_proba(X)        \n",
    "        return npy.argmax(Y)\n",
    "    \n",
    "    \n",
    "    def classify(self, file):\n",
    "        #classifies sentences within a file and returns a file of classifications denoted by 1 and 0\n",
    "        classLabels = []\n",
    "        with open(file) as f:\n",
    "            for line in f.readlines():\n",
    "                print(line,self.classification(line))\n",
    "                labels.append(self.classification(line))\n",
    "        \n",
    "        with open('results.txt', 'w') as f:\n",
    "            for label in classLabels:\n",
    "                f.write(str(label)+\"\\n\")\n",
    "                \n",
    "        print (\"Results from \",file,\" printed to: output.txt\")\n",
    "\n",
    "        \n",
    "\n",
    "print (\"Logistic Regression Model with unnormalized sentences\")\n",
    "lr_u = sentimentClass(normalize=False)\n",
    "lr_u.trainFunc([\"./sentiment_labelled_sentences/amazon_cells_labelled.txt\",\n",
    "                  \"./sentiment_labelled_sentences/imdb_labelled.txt\",\n",
    "                  \"./sentiment_labelled_sentences/yelp_labelled.txt\"])\n",
    "print()\n",
    "\n",
    "print (\"Logistic Rregression with normalized sentences\")\n",
    "lr_n = sentimentClass(normalize=True)\n",
    "lr_n.trainFunc([\"./sentiment_labelled_sentences/amazon_cells_labelled.txt\",\n",
    "                  \"./sentiment_labelled_sentences/imdb_labelled.txt\",\n",
    "                  \"./sentiment_labelled_sentences/yelp_labelled.txt\"])\n",
    "print()\n",
    "\n",
    "print (\"Naive Bayes with unnormalized sentences\")\n",
    "nb_u = sentimentClass(normalize=False, classifier='NB')\n",
    "nb_u.trainFunc([\"./sentiment_labelled_sentences/amazon_cells_labelled.txt\",\n",
    "                  \"./sentiment_labelled_sentences/imdb_labelled.txt\",\n",
    "                  \"./sentiment_labelled_sentences/yelp_labelled.txt\"])\n",
    "print()\n",
    "\n",
    "print (\"Naive Bayes with normalized sentences\")\n",
    "nb_n = sentimentClass(normalize=True, classifier='NB')\n",
    "nb_n.trainFunc([\"./sentiment_labelled_sentences/amazon_cells_labelled.txt\",\n",
    "                  \"./sentiment_labelled_sentences/imdb_labelled.txt\",\n",
    "                  \"./sentiment_labelled_sentences/yelp_labelled.txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_n.classification(\"awefully great movie\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
